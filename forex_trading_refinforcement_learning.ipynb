{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "yHKEU-tJzm4m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW3Xf8ZrzK0O",
        "outputId": "0e51cd4a-cf8c-49e8-ba5d-8d873240e734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "  import gymnasium as gym\n",
        "except:\n",
        "  !pip install gymnasium\n",
        "  import gymnasium as gym\n",
        "try:\n",
        "  import stable_baselines3\n",
        "except ImportError:\n",
        "  !pip install stable-baselines3[extra] -q\n",
        "  import stable_baselines3\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.logger import configure\n",
        "import os\n",
        "import matplotlib.dates as mdates"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collect and Extract the github"
      ],
      "metadata": {
        "id": "CsOb_Kd7zpkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory and file paths\n",
        "data_dir = \"/content/forex_data\"\n",
        "zip_file_path = \"/content/forex_data.zip\"\n",
        "zip_url = \"https://github.com/Hero988/forex-reinforcement-learning/blob/main/forex_data_pair_per_folder.zip?raw=true\"\n",
        "\n",
        "# Check if the data directory already exists\n",
        "if not os.path.exists(data_dir):\n",
        "  print(\"Data directory not found. Downloading and extracting data...\")\n",
        "\n",
        "  # Download the ZIP file\n",
        "  response = requests.get(zip_url)\n",
        "  if response.status_code == 200:\n",
        "      with open(zip_file_path, \"wb\") as zip_file:\n",
        "          zip_file.write(response.content)\n",
        "      print(\"Download complete.\")\n",
        "  else:\n",
        "      print(\"Failed to download the ZIP file. Please check the URL.\")\n",
        "      exit()\n",
        "\n",
        "  # Extract the ZIP file\n",
        "  with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
        "      zip_ref.extractall(data_dir)\n",
        "  print(f\"Data extracted to {data_dir}.\")\n",
        "\n",
        "  # Clean up the ZIP file\n",
        "  os.remove(zip_file_path)\n",
        "  print(\"ZIP file removed.\")\n",
        "else:\n",
        "  print(\"Data directory already exists. Skipping download and extraction.\")\n",
        "\n",
        "# Verify the contents of the data directory\n",
        "print(f\"Contents of {data_dir}:\")\n",
        "print(os.listdir(data_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHqSqOOjzosz",
        "outputId": "01eb33bb-fa3a-44fd-9655-63a20fa20089"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data directory not found. Downloading and extracting data...\n",
            "Download complete.\n",
            "Data extracted to /content/forex_data.\n",
            "ZIP file removed.\n",
            "Contents of /content/forex_data:\n",
            "['forex_data_pair_per_folder']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forex Trading Enviroment - Creating"
      ],
      "metadata": {
        "id": "huBv4BUU1hO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ForexTradingEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Custom Forex Trading Environment\n",
        "    \"\"\"\n",
        "    def __init__(self, df, initial_balance=10000):\n",
        "        super(ForexTradingEnv, self).__init__()\n",
        "\n",
        "        # Market data\n",
        "        self.df = df\n",
        "        self.current_step = 0\n",
        "\n",
        "        # Initial settings\n",
        "        self.initial_balance = initial_balance\n",
        "        self.balance = initial_balance\n",
        "        self.positions = 0  # Amount of currency held\n",
        "        self.net_worth = initial_balance\n",
        "\n",
        "        # Action space: [Hold, Buy, Sell]\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # Observation space: [Open, High, Low, Close, Volume, Balance, Positions]\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(6,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        \"\"\"\n",
        "        Reset the environment to the initial state.\n",
        "        \"\"\"\n",
        "        # Seeding for reproducibility\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "\n",
        "        # Reset environment state\n",
        "        self.balance = self.initial_balance\n",
        "        self.positions = 0\n",
        "        self.net_worth = self.initial_balance\n",
        "        self.current_step = 0\n",
        "        self.net_worths = [self.net_worth]  # Reset net worth tracking\n",
        "        self.rewards = []  # Reset rewards tracking\n",
        "        self.steps = [0]  # Track step numbers\n",
        "\n",
        "        # Return the initial observation and an empty info dictionary\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        \"\"\"\n",
        "        Get the next observation from the environment.\n",
        "        \"\"\"\n",
        "        data = self.df.iloc[self.current_step]\n",
        "        obs = np.array([\n",
        "            data['open'],\n",
        "            data['high'],\n",
        "            data['low'],\n",
        "            data['close'],\n",
        "            data['tick_volume'],\n",
        "            self.balance\n",
        "        ])\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Perform an action and advance the environment by one step.\n",
        "        \"\"\"\n",
        "        # Get current market data\n",
        "        data = self.df.iloc[self.current_step]\n",
        "        current_price = data['close']\n",
        "\n",
        "        # Calculate reward\n",
        "        reward = 0\n",
        "        if action == 1:  # Buy\n",
        "            self.positions += self.balance / current_price\n",
        "            self.balance = 0\n",
        "        elif action == 2:  # Sell\n",
        "            self.balance += self.positions * current_price\n",
        "            self.positions = 0\n",
        "        self.net_worth = self.balance + self.positions * current_price\n",
        "        reward = self.net_worth - self.net_worths[-1]  # Reward is the change in net worth\n",
        "\n",
        "        # Track performance\n",
        "        self.net_worths.append(self.net_worth)\n",
        "        self.rewards.append(reward)\n",
        "        self.steps.append(self.current_step)\n",
        "\n",
        "        # Get the current time\n",
        "        current_time = data['time']  # Ensure the 'time' column exists in your DataFrame\n",
        "\n",
        "        # Move to the next step\n",
        "        self.current_step += 1\n",
        "        terminated = self.current_step >= len(self.df) - 1\n",
        "        truncated = False  # Add a placeholder for the truncated flag\n",
        "\n",
        "        # Return observation, reward, terminated, truncated, and info\n",
        "        return (\n",
        "            self._next_observation(),\n",
        "            reward,\n",
        "            terminated,\n",
        "            truncated,\n",
        "            {\"net_worth\": self.net_worth, \"time\": current_time},\n",
        "        )\n",
        "\n"
      ],
      "metadata": {
        "id": "c1v7FsNj0Xn4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluating"
      ],
      "metadata": {
        "id": "jgEMtQ_w3vjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_performance(times, net_worths, rewards, output_dir):\n",
        "  \"\"\"\n",
        "  Plot net worth and rewards over time.\n",
        "  \"\"\"\n",
        "  # Convert times to datetime if not already\n",
        "  if isinstance(times[0], str):\n",
        "      times = pd.to_datetime(times)\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "\n",
        "  # Plot net worth over time\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.plot(times, net_worths, label=\"Net Worth\", color=\"blue\")\n",
        "  plt.title(\"Net Worth Over Time\")\n",
        "  plt.xlabel(\"Time\")\n",
        "  plt.ylabel(\"Net Worth\")\n",
        "  plt.legend()\n",
        "  plt.grid()\n",
        "  plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
        "  plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
        "  plt.xticks(rotation=45)\n",
        "\n",
        "  # Plot rewards over time\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.plot(times, rewards, label=\"Rewards\", color=\"green\")\n",
        "  plt.title(\"Rewards Over Time\")\n",
        "  plt.xlabel(\"Time\")\n",
        "  plt.ylabel(\"Reward\")\n",
        "  plt.legend()\n",
        "  plt.grid()\n",
        "  plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
        "  plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
        "  plt.xticks(rotation=45)\n",
        "\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Save the plot to the output directory\n",
        "  plt.savefig(os.path.join(output_dir, \"equity_plot.png\"))\n",
        "  plt.close()\n"
      ],
      "metadata": {
        "id": "6Gq_vYIEguZo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_save(data_dir, output_dir, timesteps=800000):\n",
        "  os.makedirs(output_dir, exist_ok=True)  # Ensure the main output directory exists\n",
        "  for pair_folder in os.listdir(data_dir):\n",
        "      pair_path = os.path.join(data_dir, pair_folder)\n",
        "      if not os.path.isdir(pair_path):\n",
        "          continue\n",
        "\n",
        "      # Create a subfolder inside output_dir for the pair_folder\n",
        "      pair_output_dir = os.path.join(output_dir, pair_folder)\n",
        "      os.makedirs(pair_output_dir, exist_ok=True)\n",
        "\n",
        "      # Load Data\n",
        "      five_years_data_path = os.path.join(pair_path, f\"{pair_folder}_5_years.csv\")\n",
        "      one_year_data_path = os.path.join(pair_path, f\"{pair_folder}_2024_present.csv\")\n",
        "      if not os.path.exists(five_years_data_path) or not os.path.exists(one_year_data_path):\n",
        "          print(f\"Data files missing for {pair_folder}\")\n",
        "          continue\n",
        "\n",
        "      df_train = pd.read_csv(five_years_data_path)\n",
        "      df_eval = pd.read_csv(one_year_data_path)\n",
        "\n",
        "      # Initialize Environment\n",
        "      env_training = DummyVecEnv([lambda: ForexTradingEnv(df_train)])\n",
        "      env_evaluating = DummyVecEnv([lambda: ForexTradingEnv(df_eval)])\n",
        "\n",
        "      # Train Model\n",
        "      model = DQN(\"MlpPolicy\", env_training, verbose=1)\n",
        "      model.learn(total_timesteps=timesteps)\n",
        "\n",
        "      # Save Model in pair's subfolder\n",
        "      model_save_path = os.path.join(pair_output_dir, f\"{pair_folder}_dqn_model\")\n",
        "      model.save(model_save_path)\n",
        "\n",
        "      # Evaluate Model\n",
        "      obs = env_evaluating.reset()\n",
        "      total_reward, net_worths, rewards, times = 0, [], [], []\n",
        "      while True:\n",
        "          action, _ = model.predict(obs, deterministic=True)\n",
        "          obs, reward, done, info = env_evaluating.step(action)  # Only 4 values are unpacked\n",
        "\n",
        "          # Extract values from vectorized environment\n",
        "          reward = reward[0]\n",
        "          done = done[0]\n",
        "          info = info[0]\n",
        "\n",
        "          # Track performance\n",
        "          net_worths.append(info[\"net_worth\"])\n",
        "          rewards.append(reward)\n",
        "          times.append(info[\"time\"])\n",
        "          total_reward += reward\n",
        "\n",
        "          # Check termination\n",
        "          if done:\n",
        "              break\n",
        "\n",
        "      # Save Trade Diary in pair's subfolder\n",
        "      trade_diary_path = os.path.join(pair_output_dir, f\"{pair_folder}_trade_diary.csv\")\n",
        "      trade_diary = pd.DataFrame({\"Time\": times, \"Net Worth\": net_worths, \"Reward\": rewards})\n",
        "      trade_diary.to_csv(trade_diary_path, index=False)\n",
        "\n",
        "      # Save Equity Plot in pair's subfolder\n",
        "      plot_performance(times, net_worths, rewards, pair_output_dir)\n",
        "\n",
        "      print(f\"Completed training and evaluation for {pair_folder}\")"
      ],
      "metadata": {
        "id": "Cp1-ZY-M9J9s"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Execution\n",
        "data_directory = \"forex_data/forex_data_pair_per_folder\"\n",
        "output_directory = \"forex_results\"\n",
        "train_evaluate_save(data_directory, output_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6vS2adjZ3z--",
        "outputId": "3bcd531a-91ea-42ff-f682-e3c326ce8d08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 786      |\n",
            "|    time_elapsed     | 189      |\n",
            "|    total_timesteps  | 149276   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.97     |\n",
            "|    n_updates        | 37293    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 752      |\n",
            "|    time_elapsed     | 396      |\n",
            "|    total_timesteps  | 298552   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.41     |\n",
            "|    n_updates        | 74612    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 742      |\n",
            "|    time_elapsed     | 603      |\n",
            "|    total_timesteps  | 447828   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.41     |\n",
            "|    n_updates        | 111931   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 736      |\n",
            "|    time_elapsed     | 810      |\n",
            "|    total_timesteps  | 597104   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.53     |\n",
            "|    n_updates        | 149250   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 734      |\n",
            "|    time_elapsed     | 1016     |\n",
            "|    total_timesteps  | 746380   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.93     |\n",
            "|    n_updates        | 186569   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 731      |\n",
            "|    time_elapsed     | 1223     |\n",
            "|    total_timesteps  | 895656   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.49     |\n",
            "|    n_updates        | 223888   |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b2ccf50ac418>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/forex_data/forex_data_pair_per_folder\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"forex_results\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_evaluate_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-3655baf113dd>\u001b[0m in \u001b[0;36mtrain_evaluate_save\u001b[0;34m(data_dir, output_dir, timesteps)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MlpPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;31m# Save Model in pair's subfolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     ) -> SelfDQN:\n\u001b[0;32m--> 267\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             rollout = self.collect_rollouts(\n\u001b[0m\u001b[1;32m    329\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mtrain_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;31m# Rescale and perform action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-3-f73e15f16930>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Get current market data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mcurrent_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1752\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3994\u001b[0m         \u001b[0;31m# irow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3995\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3996\u001b[0;31m             \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3998\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m         \u001b[0mbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockPlacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwDr6QTT7-Dq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}